 ,v
    ,V
   ,V
        fv_space = []        self.label_space = []        for fv in training:            fv_space.append(fv.vector)            self.label_space.append(fv.topics)        clf = tree.DecisionTreeClassifier()        self.dt = clf.fit(fv_space, self.label_space),v
        self.training = training,V
,V
    def __euclidean_distance(self,x1, x2):        """ function: euclidean_distance            ----------------------------            compute the distance between @x1 and @x2            :param x1: list of dimensions of a vector            :param x2: list of dimensions of a vector            :returns: float representing distance between @x1 and @x1        """        distance = 0.0        for i in range(len(x1)):            distance += pow( x1[i] - x2[i], 2)        return math.sqrt(distance)    def __get_knn(self,test):        """ function: get_knn            -----------------            get k nearest points in @training to the point @test            :param test: one feature vector to match to model            :returns: list of class labels of k nearest neighbors        """        distances = []        for point in self.training:            dist = self.__euclidean_distance(test.vector,point.vector)            distances.append((point.topics,dist))        distances.sort(key=operator.itemgetter(1))        class_labels = []        for x in range(self.num_neighbors):            class_labels += distances[x][0]        return class_labels,v
    def __run_tree(self,test):        """ function: run_tree            ------------------            generate list of labels for a @test vector based on self.dt            :param test: one feature vector to match to model            :returns: list of class labels of decision tree traversal        """        probabilities = self.dt.predict_proba([test.vector])        class_labels = []        for i, p in enumerate(probabilities[0]):            if p > self.epsilon:                class_labels += self.label_space[i]        return class_labels,v
function -;     cd -; end,V
# -p "mI;queM]ent:Yorl<iJ/manK)od]voS<E?Ob>yI.",V
# -u ankailou@gmail.com,V
. $HOME/.config/fish/functions/export.fish,V
. $HOME/.config/fish/functions/util.fish,V
# Login Hookif status --is-login  # Language Default  set -x LC_ALL en_US.UTF-8  set -x LC_CTYYPE en_US.UTF-8  # Homebrew  set -x PATH $PATH /usr/local/bin  set -x PATH $PATH /usr/bin  set -x PATH $PATH /usr/sbin  set -x PATH $PATH /usr/texbin  set -x PATH $PATH /bin  set -x PATH $PATH /sbin  # Ruby  set -x PATH $PATH $HOME/.rbenv/bin  set -x PATH $PATH $HOME/.rbenv/shims  set -x RUBY_GC_HEAP_INIT_SLOTS 600000  set -x RUBY_GC_HEAP_FREE_SLOTS 600000  set -x RUBY_GC_HEAP_GROWTH_FACTOR 1.25  set -x RUBY_GC_HEAP_GROWTH_MAX_SLOTS 300000  # Python  set -x PATH $PATH $HOME/.pyenv  # Go  set -x GOPATH $HOME/Documents/dev/go  set -x PATH $PATH $GOPATH/bin  # Android  set -x ANDROID_HOME /usr/local/opt/android-sdk  # Editor  set -x EDITOR "vim"  # Less  set -x LESS "-RSM~gIsw"end,v
# Function for general conveniencefunction md; mkdir -p "$argv"; cd "$argv"; endfunction c;  tr -d '\n' | pbcopy $argv; end# Running State Functionsfunction ps;    command ps -SAcr -o 'uid,pid,ppid,time,rss,command'; endfunction psef;  ps -ef | grep $argv; end# Open Functionsfunction o;    open $argv; endfunction oo;   open . $argv; endfunction ios;  open /Applications/Xcode.app/Contents/Developer/Applications/Simulator.app; endfunction pman; man -t $argv | open -f -a /Applications/Preview.app; end# Goto Folderfunction dl;     cd ~/Downloads; endfunction drive;  cd ~/Google\ Drive; end# General Housekeeping & Utilitiesfunction sleep;    pmset sleepnow; endfunction stdlinux; ssh loua@stdlinux.cse.ohio-state.edu; endfunction flush;    dscacheutil -flushcache $argv; endfunction cleanup;  find . -type f -name '*.DS_Store' -ls -delete; endfunction empty-trash --description 'empty OS X trash folders'  sudo rm -rfv /Volumes/*/.Trashes  sudo rm -rfv ~/.Trash  sudo rm -rfv /private/var/log/asl/*.aslendfunction spoton;  sudo mdutil -a -i on; endfunction spotoff; sudo mdutil -a -i off; end# Public Keyfunction public-key; pbcopy < ~/.ssh/id_rsa.pub; end,v
. $HOME/.config/fish/functions/tree.fish,V
# Aliasesalias j jobsalias m mailalias h historyalias :q exitalias :qa exit,v
# Parent Directory Functionsfunction -;     cd -; endfunction ..;    cd ..; endfunction ...;   cd ../..; endfunction ....;  cd ../../..; endfunction .....; cd ../../../..; end,v
. $HOME/.config/fish/functions/edit.fish,V
# Tree Functionsfunction tree1;  tree --dirsfirst -ChFLQ 1 $argv; endfunction tree2;  tree --dirsfirst -ChFLQ 2 $argv; endfunction tree3;  tree --dirsfirst -ChFLQ 3 $argv; endfunction tree4;  tree --dirsfirst -ChFLQ 4 $argv; endfunction tree5;  tree --dirsfirst -ChFLQ 5 $argv; endfunction tree6;  tree --dirsfirst -ChFLQ 6 $argv; end,v
# Edit Functionsfunction ef;  vim ~/.config/fish/config.fish; endfunction eff; vim ~/.config/fish/functions; endfunction ev;  vim ~/.vim/vimrc; endfunction egv; vim ~/.vim/gvimrc; endfunction ed;  vim ~/.vim/custom-dictionary.utf-8.add; endfunction et;  vim ~/.tmux.conf; endfunction eg;  vim ~/.gitconfig; endfunction ec;  env EDITOR=vim crontab -e; end# Source Functionsfunction sf;   source ~/.config/fish/config.fish; end,v
# Git Functions#function ga;   git add $argv; end#function gc;   git commit $argv; end#function gp;   git push $argv; end#function gpt;  git push --tags $argv; end#function gpl;  git pull --prune; end#function gl;   git log --graph --pretty=format:'%Cred%h%Creset %an: %s - %Creset %C(yellow)%d%Creset %Cgreen(%cr)%Creset' --abbrev-commit --date=relative; end#function gd;   git diff $argv; end#function gdc;  git diff --cached $argv; end#function gch;  git checkout $argv; end#function gchb; git checkout -b $argv; end#function gb;   git branch $argv; end#function gs;   git status -sb; end#function grs;  git reset --soft $argv; end#function grs;  git reset --hard $argv; end#function gcp;  git cherry-pick $argv; end,v
# Git Functionsfunction ga;   git add $argv; endfunction gc;   git commit $argv; endfunction gp;   git push $argv; endfunction gpt;  git push --tags $argv; endfunction gpl;  git pull --prune; endfunction gl;   git log --graph --pretty=format:'%Cred%h%Creset %an: %s - %Creset %C(yellow)%d%Creset %Cgreen(%cr)%Creset' --abbrev-commit --date=relative; endfunction gd;   git diff $argv; endfunction gdc;  git diff --cached $argv; endfunction gch;  git checkout $argv; endfunction gchb; git checkout -b $argv; endfunction gb;   git branch $argv; endfunction gs;   git status -sb; endfunction grs;  git reset --soft $argv; endfunction grs;  git reset --hard $argv; endfunction gcp;  git cherry-pick $argv; end,v
function egrep; command egrep --color-auto; end,V
function fgrep; command fgrep --color-auto; end,V
# Grep Functions,V
  set -x PATH $PATH /usr/local/sbin,V
  tree --dirsfirst -ChFLQ 1 $argv; end,v
function tree,V
function pman; man -t $argv | open -f -a /Applications/Preview.app; end,V
function ios; open /Applications/Xcode.app/Contents/Developer/Applications/Simulator.app; end,V
function empty-trash --description 'empty OS X trash folders'  sudo rm -rfv /Volumes/*/.Trashes  sudo rm -rfv ~/.Trash  sudo rm -rfv /private/var/log/asl/*.aslend,v
function sleep; pmset sleepnow; end,V
~/Documents/My\ Games/Pokemon\ Showdown/Teams/*;,v
~/Google\ Drive/Pokemon/$gen/$team,v
            echo "Loading Generation $i Teams...",V
            set -g gen 'Generation II',V
    echo $argv[2..-1],V
    echo $arg[2..1],V
  if test (count $argv) -eq 0    echo 'error: provide a url to a niconico video'  else    youtube-dl --extract-audio --audio-format mp3 $argv  end,v
  if test (count $argv) -eq 0    youtube-dl -o "~/Movies/YouTube/%(title)s-%(id)s.%(ext)s" :ytwatchlater  else    youtube-dl -o "~/Movies/YouTube/%(title)s-%(id)s.%(ext)s" $argv  end,v
          echo "No template given. Defaulting to template-pset.tex...",V
  switch (command pwd)    case '*/Documents/doc/tex*'      set -g name "default"      set -g temp "pset"      if test (count $argv) -eq 1        echo "No template given. Defaulting to template-pset.tex..."        set -g name $argv      else if test (count $argv) -gt 1        set -g name "$argv[1]"        set -g temp "$argv[2]"        echo "Generating $name.tex file from template-$temp.tex..."      end      cp ~/Documents/doc/tex/template/template-$temp.tex $name.tex      vim $name.tex    case '*'      echo ''Error: keep .tex files in the correct directory! Defaulting to base directory...      tex      tex-init $argv  end,v
  find ~/Documents/doc/tex -type f -name '*.aux' -ls -delete;  find ~/Documents/doc/tex -type f -name '*.fls' -ls -delete;  find ~/Documents/doc/tex -type f -name '*.log' -ls -delete;  find ~/Documents/doc/tex -type f -name '*.synctex.gz' -ls -delete;  find ~/Documents/doc/tex -type f -name '*.fdb_latexmk' -ls -delete;,v
    int numBoxes, numRows, numCols;    int id, x, y, height, width, numNeighbor, tmp, dsv;    // grab overall grid parameters    cout << "Enter grid parameters (boxes, rows, columns):" << endl;    cin >> numBoxes >> numRows >> numCols;    // grab individual box parameters    cout << "Enter initial box parameters (-1 to quit):" << endl;    cin >> id;    while ( id != -1 ) {        // instantiate new box object;        Box box;        // read parameter values & set;        cin >> x >> y >> height >> width;        box.setParameters(x, y, height, width);        // get neighbors;        vector<int> neighbors;        for (int i = 0; i < NUM_SIDES; i++) {            cin >> numNeighbor;            for (int j = 0; j < numNeighbor; j++) {                cin >> tmp;                neighbors.push_back(tmp);            }            box.setNeighbors(i, numNeighbor, neighbors);        }        // get dsv temperate as int; convert to float;        cin >> dsv;        box.setDSV(dsv);        // insert (id, box) pair into Boxes map;        Boxes[id] = box;        // reread id number or quit signal        cout << "Enter initial box parameters (-1 to quit):" << endl;        cin >> id;    },v
),v
(,v
    cout << "Enter initial box parameters (-1 to quit):" << endl;,V
    int *neighborsdd;,V
\address{Expected Graduation in May 2016},V
#include <vector>,v
neighbors.data();,v
 cin >> num_neighbor >> neighborVector;        box.setNeighbor(0, numNeighbor, neighbors);,v
void Box::setNeighbors(int id) {    int *neighbors;    switch (id) {        case 0:            neighbors = this->top_neighbor;            break;        case 1:            neighbors = this->left_neighbor;            break;        case 2:            neighbors = this->right_neighbor;            break;        case 3:            neighbors = this->bottom_neighbor;            break;        default:            break;    }    return neighbors;},v
        setNeighbors(int),V
void Box::getID() {    return this->id;},v
ls -l --group-directories-first,v
            print '\n',feature_set,V
                print feature,V
 print 'Writing feature vector data @', datafile    __generate_csv(datafile, selector.features, selector.feature_vectors)    print 'Finished generating dataset @', datafile,v
    """    # extract out vectors with empty 'topics' class labels    fv, efv = __filter_empty(feature_vectors)    pfv, epfv = __filter_empty(pared_feature_vectors)    # implement cross validation with n = 5 or n = 10    cross_validator = CrossValidator(fv,num_partitions)    pared_cross_validator = CrossValidator(pfv,num_partitions)    # knn on @feature_vectors    print('\nExperiment: k-nearest-neighbor on standard feature vector...')    cross_validator.classify(KNN(num_neighbors))    # knn on @pared_feature_vectors    print('\nExperiment: k-nearest-neighbor on pared down feature vector...')    pared_cross_validator.classify(KNN(num_neighbors))    # decision-tree on @feature_vectors    print('\nExperiment: decision tree on standard feature vector...')    cross_validator.classify(DecisionTree(epsilon))    # decision-tree on @pared_feature_vectors    print('\nExperiment: decision tree on pared down feature vector...')    pared_cross_validator.classify(DecisionTree(epsilon))    # bayesian on @feature vectors    print('\nExperiment: bayesian on standard feature vector...')    cross_validator.classify(Bayesian(epsilon))    # bayesian on @pared_feature_vectors    print('\nExperiment: bayesian on pared down feature vector...')    pared_cross_validator.classify(Bayesian(epsilon))    """,v
0.898412698413,v
6.91413879395e-06,v
##################################################################################################################,V
\begin{rSection}{Projects}  \begin{rSubsection}{SmogTour Usage Stats}{January 2013 - Present}{}{}  \item Implemented scripts for compiling tournament usage stats from Smogon's Pokemon Showdown server     (http://smogtours.psim.us) --- deflated original repo by 80\% and cut runtime down by 50\%.  \item Experimented with clustering and classification techniques to compile \& extract metagame trends.  \item Began work on a web crawler that applied usage stats \& machine learning concepts to play matches.  \end{rSubsection}\end{rSection},v
Machine Learning & Statistical Pattern Recognition,v
resume.cls,v
Databases & SQLite, PostgreSQL, MongoDB, Redis,V
  Coursework Emphasis on Data Mining, Machine Learning, \& High Performance Computing\smallskip \\,V
http://smogtours.psim.us,v
Scripts for compiling usage stats from Smogon's Pokemon Showdown server,v
  \item,V
  Tools \& Technology & Git, Puppet, AJAX, Unix,V
\begin{rSubsection}{Ohio State University, Department of Computer Science}{January 2014 - April 2015}{Student Instructional Assistant}{Columbus, OH}\item Vivamus PostgreSQL fermentum semper porta. Nunc diam velit PHP, adipiscing ut tristique vitae\end{rSubsection},v
\item Curabitur venenatis pulvinar tellus gravida ornare. Sed et erat faucibus nunc euismod ultricies ut id,V
\item Quisque mi metus, unit tests CSS ornare sit amet fermentum et, tincidunt et orci.,V
\item Maecenas convallis ullamcorper ultricies stylesheets.,V
\item Curabitur dapibus enim sit amet elit pharetra tincidunt website feugiat nisl imperdiet. Ut convallis AJAX libero in urna ultrices accumsan.,V
\item Cum sociis natoque penatibus et magnis dis MySQL parturient montes, nascetur ridiculus mus.,V
\item In rutrum accumsan ultricies. Mauris vitae nisi at sem facilisis semper ac in est.,V
  dd\item Nullam cursus suscipit nisi, et ultrices justo sodales nec. Fusce venenatis facilisis lectus ac semper.,V
  \item Donec et mollis dolor. Praesent et diam eget libero Adobe Coldfusion egestas mattis sit amet vitae augue.  \item Nam tincidunt congue enim, ut porta lorem Microsoft SQL lacinia consectetur.  \item Donec ut libero sed arcu vehicula ultricies a non tortor. Lorem ipsum dolor sit amet, consectetur adipiscing elit.  \item Pellentes,v
PNC Financial Services Group, Inc.,v
administrator,v
\resheading{Objective},V
\begin{itemize},V
\item Seeking admittance to the Piazza Tech Tour for the Winter of 2015.,V
\end{itemize},V
.DS_Store*~*.swp,v
"git log --graph --pretty=format:'%Cred%h%Creset %an: %s - %Creset %C(yellow)%d%Creset %Cgreen(%cr)%Creset' --    abbrev-commit --date=relative",v
g,v
open /Applications/Xcode.app/Contents/Applications/iOS\ Simulator.app,v
import sys,V
import os,V
###############################################################################,V
####### modules & libraries required for feature reduction & selection ########,V
import threading # will potentially use multi-threading,V
    # decision_tree(pared_cross_validator.partitions),V
    # decision_tree(cross_validator.partitions),V
#################################################################################################### function(s) for knn classification #####################################################################################################def generate_decision_tree(training):    """ function: generate_decision_tree        --------------------------------        generate sklearn decision tree from training set of feature vectors        :param training: dataset of feature vector & labels for the model        :returns: decision tree object to be used for classification    """    fv_space = []    label_space = []    for fv in training:        fv_space.append(fv.vector)        label_space.append(fv.topics)    clf = tree.DecisionTreeClassifier()    clf = clf.fit(fv_space, label_space)    return clf, label_spacedef dt_classify(label_space, probabilities):    """ function: dt_classify        ---------------------        generate class labels from probability vector        :param label_space: vector of labels to be reduced for classification        :param probability: vector of probabilities for giving classifications        :returns: list of class labels of k nearest neighbors    """    class_labels = []    for i, p in enumerate(probabilities):        if p > epsilon:            class_labels.append(label_space[i])    return class_labelsdef decision_tree(partitions):    """ function: decision_tree        -----------------------        use decision-tree classifier via cross-validation on feature vectors        :param partitions: dictionary representing feature vector dataset    """    average_offline = 0.0    average_online = 0.0    average_accuracy = 0.0    # cross-validation across partitions    for i in xrange(num_partitions):        test = partitions[i]        # build model - get offline cost        offline_start = time.time()        training = []        for j in xrange(num_partitions):            if j != i:                training += partitions[j]        dt, label_space = generate_decision_tree(training)        offline_total = time.time() - offline_start        average_offline += offline_total        print 'Offline cost for trial', i, '-', offline_total, 'seconds'        # test classifier - get online cost        online_start = time.time()        accuracy = 0.0        for fv in test:            probabilities = dt.predict_proba([fv.vector])            # classify            labels = dt_classify(label_space, probabilities[0])            # check accuracy            if len(set(labels[0]) & set(fv.topics)) > 0:                accuracy += 1.0        average_accuracy += accuracy / len(test)        print 'Total accuracy of trial', i, '-', accuracy / len(test)        online_total = time.time() - online_start        average_online += online_total        print 'Online cost for trial', i, '-', online_total, 'seconds'    # compute final statistics    average_offline /= num_partitions    average_online /= num_partitions    average_accuracy /= num_partitions    print 'Average offline efficiency cost:', average_offline, 'seconds'    print 'Average online efficiency cost:', average_online, 'seconds'    print 'Average accuracy of the classifier:', average_accuracy,v
